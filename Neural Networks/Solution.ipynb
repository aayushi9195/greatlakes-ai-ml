{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 1\n",
    "\n",
    "# Loading up the csv file\n",
    "stock_prices_df = pd.read_csv('prices.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-05 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-06 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-07 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-08 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-11 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date symbol        open       close         low        high  \\\n",
       "0  2016-01-05 00:00:00   WLTW  123.430000  125.839996  122.309998  126.250000   \n",
       "1  2016-01-06 00:00:00   WLTW  125.239998  119.980003  119.940002  125.540001   \n",
       "2  2016-01-07 00:00:00   WLTW  116.379997  114.949997  114.930000  119.739998   \n",
       "3  2016-01-08 00:00:00   WLTW  115.480003  116.620003  113.500000  117.440002   \n",
       "4  2016-01-11 00:00:00   WLTW  117.010002  114.970001  114.089996  117.330002   \n",
       "\n",
       "      volume  \n",
       "0  2163600.0  \n",
       "1  2386400.0  \n",
       "2  2489500.0  \n",
       "3  2006300.0  \n",
       "4  1408600.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking that the dataframe is initialised correctly\n",
    "stock_prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(851264, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of rows and columns\n",
    "stock_prices_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 851264 entries, 0 to 851263\n",
      "Data columns (total 7 columns):\n",
      "date      851264 non-null object\n",
      "symbol    851264 non-null object\n",
      "open      851264 non-null float64\n",
      "close     851264 non-null float64\n",
      "low       851264 non-null float64\n",
      "high      851264 non-null float64\n",
      "volume    851264 non-null float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 45.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking the info\n",
    "stock_prices_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>open</td>\n",
       "      <td>851264.0</td>\n",
       "      <td>7.083699e+01</td>\n",
       "      <td>8.369588e+01</td>\n",
       "      <td>0.85</td>\n",
       "      <td>3.384000e+01</td>\n",
       "      <td>5.277000e+01</td>\n",
       "      <td>7.988000e+01</td>\n",
       "      <td>1.584440e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>close</td>\n",
       "      <td>851264.0</td>\n",
       "      <td>7.085711e+01</td>\n",
       "      <td>8.368969e+01</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.385000e+01</td>\n",
       "      <td>5.280000e+01</td>\n",
       "      <td>7.989000e+01</td>\n",
       "      <td>1.578130e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>low</td>\n",
       "      <td>851264.0</td>\n",
       "      <td>7.011841e+01</td>\n",
       "      <td>8.287729e+01</td>\n",
       "      <td>0.83</td>\n",
       "      <td>3.348000e+01</td>\n",
       "      <td>5.223000e+01</td>\n",
       "      <td>7.911000e+01</td>\n",
       "      <td>1.549940e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>high</td>\n",
       "      <td>851264.0</td>\n",
       "      <td>7.154348e+01</td>\n",
       "      <td>8.446550e+01</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.419000e+01</td>\n",
       "      <td>5.331000e+01</td>\n",
       "      <td>8.061000e+01</td>\n",
       "      <td>1.600930e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>volume</td>\n",
       "      <td>851264.0</td>\n",
       "      <td>5.415113e+06</td>\n",
       "      <td>1.249468e+07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.221500e+06</td>\n",
       "      <td>2.476250e+06</td>\n",
       "      <td>5.222500e+06</td>\n",
       "      <td>8.596434e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std   min           25%  \\\n",
       "open    851264.0  7.083699e+01  8.369588e+01  0.85  3.384000e+01   \n",
       "close   851264.0  7.085711e+01  8.368969e+01  0.86  3.385000e+01   \n",
       "low     851264.0  7.011841e+01  8.287729e+01  0.83  3.348000e+01   \n",
       "high    851264.0  7.154348e+01  8.446550e+01  0.88  3.419000e+01   \n",
       "volume  851264.0  5.415113e+06  1.249468e+07  0.00  1.221500e+06   \n",
       "\n",
       "                 50%           75%           max  \n",
       "open    5.277000e+01  7.988000e+01  1.584440e+03  \n",
       "close   5.280000e+01  7.989000e+01  1.578130e+03  \n",
       "low     5.223000e+01  7.911000e+01  1.549940e+03  \n",
       "high    5.331000e+01  8.061000e+01  1.600930e+03  \n",
       "volume  2.476250e+06  5.222500e+06  8.596434e+08  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking statistical summary\n",
    "stock_prices_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the features show a similar distribution - the mean values > median which implies a tail on the right. \n",
    "# There is a significant difference between min and max values.\n",
    "# The values of volume are far greater than those of other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>open</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>-0.059950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>close</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>-0.060154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>low</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.999928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>-0.060760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>high</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.999927</td>\n",
       "      <td>0.999892</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>volume</td>\n",
       "      <td>-0.059950</td>\n",
       "      <td>-0.060154</td>\n",
       "      <td>-0.060760</td>\n",
       "      <td>-0.059452</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            open     close       low      high    volume\n",
       "open    1.000000  0.999849  0.999916  0.999930 -0.059950\n",
       "close   0.999849  1.000000  0.999928  0.999927 -0.060154\n",
       "low     0.999916  0.999928  1.000000  0.999892 -0.060760\n",
       "high    0.999930  0.999927  0.999892  1.000000 -0.059452\n",
       "volume -0.059950 -0.060154 -0.060760 -0.059452  1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking co-relations\n",
    "stock_prices_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open, close, low and high are highly co-related with each other and also with the target.\n",
    "# Volume does not have a strong relation with any other feature or target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 2\n",
    "\n",
    "# Checking for null values\n",
    "stock_prices_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are no null values to drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3\n",
    "\n",
    "# Dropping string types and low co-relation columns\n",
    "stock_prices_df = stock_prices_df.drop(['date','symbol','volume'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(851264, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape again\n",
    "stock_prices_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(851264, 3) (851264,)\n"
     ]
    }
   ],
   "source": [
    "# Answer 4\n",
    "\n",
    "# Separating features from target variable\n",
    "X = stock_prices_df.drop('close', axis=1)\n",
    "y = stock_prices_df['close']\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595884, 3) (595884,) (255380, 3) (255380,)\n"
     ]
    }
   ],
   "source": [
    "# Answer 5\n",
    "\n",
    "# Splitting the data into train and test\n",
    "test = 0.3\n",
    "seed = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test, random_state=seed)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 6\n",
    "\n",
    "# Scaling the features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 7\n",
    "\n",
    "# Converting features and labels into numpy array\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595884, 3, 1) (255380, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Answer 8\n",
    "\n",
    "# Reshaping the features for input in the neural network model \n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 9\n",
    "\n",
    "# Defining the sequential model\n",
    "model = Sequential()\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 10\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary is printed after model fitting and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "595884/595884 [==============================] - 9s 14us/step - loss: 41.0682 0s - loss:\n",
      "Epoch 2/50\n",
      "595884/595884 [==============================] - 7s 12us/step - loss: 0.9611\n",
      "Epoch 3/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.9548\n",
      "Epoch 4/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.9462\n",
      "Epoch 5/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.9409\n",
      "Epoch 6/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.9339\n",
      "Epoch 7/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.9265\n",
      "Epoch 8/50\n",
      "595884/595884 [==============================] - 7s 12us/step - loss: 0.9207\n",
      "Epoch 9/50\n",
      "595884/595884 [==============================] - 7s 11us/step - loss: 0.9170\n",
      "Epoch 10/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.9098\n",
      "Epoch 11/50\n",
      "595884/595884 [==============================] - 9s 16us/step - loss: 0.9021\n",
      "Epoch 12/50\n",
      "595884/595884 [==============================] - 9s 15us/step - loss: 0.8968\n",
      "Epoch 13/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.8913\n",
      "Epoch 14/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.8837\n",
      "Epoch 15/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.8792\n",
      "Epoch 16/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.8745\n",
      "Epoch 17/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.8685\n",
      "Epoch 18/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.8622\n",
      "Epoch 19/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.8560\n",
      "Epoch 20/50\n",
      "595884/595884 [==============================] - 9s 15us/step - loss: 0.8506\n",
      "Epoch 21/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.8466\n",
      "Epoch 22/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.8417\n",
      "Epoch 23/50\n",
      "595884/595884 [==============================] - 7s 12us/step - loss: 0.8346\n",
      "Epoch 24/50\n",
      "595884/595884 [==============================] - 6s 10us/step - loss: 0.8303\n",
      "Epoch 25/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.8247\n",
      "Epoch 26/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.8196\n",
      "Epoch 27/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.8154\n",
      "Epoch 28/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.8106\n",
      "Epoch 29/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.8069\n",
      "Epoch 30/50\n",
      "595884/595884 [==============================] - 7s 12us/step - loss: 0.8001: 0s -\n",
      "Epoch 31/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.7961\n",
      "Epoch 32/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.7904:\n",
      "Epoch 33/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.7867\n",
      "Epoch 34/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.7816\n",
      "Epoch 35/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.7767\n",
      "Epoch 36/50\n",
      "595884/595884 [==============================] - 7s 12us/step - loss: 0.7729\n",
      "Epoch 37/50\n",
      "595884/595884 [==============================] - 7s 12us/step - loss: 0.7703\n",
      "Epoch 38/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.7650\n",
      "Epoch 39/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.7604\n",
      "Epoch 40/50\n",
      "595884/595884 [==============================] - 7s 12us/step - loss: 0.7553\n",
      "Epoch 41/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.7526\n",
      "Epoch 42/50\n",
      "595884/595884 [==============================] - 7s 13us/step - loss: 0.7476\n",
      "Epoch 43/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.7436\n",
      "Epoch 44/50\n",
      "595884/595884 [==============================] - 7s 12us/step - loss: 0.7396\n",
      "Epoch 45/50\n",
      "595884/595884 [==============================] - 7s 12us/step - loss: 0.7358\n",
      "Epoch 46/50\n",
      "595884/595884 [==============================] - 7s 12us/step - loss: 0.7324\n",
      "Epoch 47/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.7279\n",
      "Epoch 48/50\n",
      "595884/595884 [==============================] - 8s 13us/step - loss: 0.7245\n",
      "Epoch 49/50\n",
      "595884/595884 [==============================] - 7s 13us/step - loss: 0.7203\n",
      "Epoch 50/50\n",
      "595884/595884 [==============================] - 8s 14us/step - loss: 0.7161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2978e42af48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer 12\n",
    "\n",
    "# Fitting the model on train data\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255380/255380 [==============================] - 6s 23us/step\n",
      "Loss on test:  0.7452197583245077\n",
      "RMSE on train:  0.8414695399683783\n",
      "RMSE on test:  0.8632611278628417\n"
     ]
    }
   ],
   "source": [
    "# Answer 13\n",
    "\n",
    "# model.metrics_names = 'Loss' for this dataset\n",
    "# Evaluating the model on test data\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print('Loss on test: ', loss)\n",
    "\n",
    "# Predicting the output on test data\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Calculating the root mean squared error on train data\n",
    "y_pred_train = model.predict(X_train)\n",
    "rmse_train = sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "print('RMSE on train: ', rmse_train)\n",
    "\n",
    "# Calculating the root mean squared error on test data\n",
    "rmse_test = sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "print('RMSE on test: ', rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The difference between RMSE of train and test data is not too high, this implies that our model does not overfit.\n",
    "# Also, as the target variables are not scaled, they have a wide range of 0.86 going up to 1578. With respect to this scale,\n",
    "# RMSE is quite low (Ref: https://stats.stackexchange.com/questions/56302/what-are-good-rmse-values).\n",
    "# We can confirm this by comparing some actual and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Actual   Predicted\n",
      "0        40.020000   40.345940\n",
      "1       292.440002  292.763794\n",
      "2        71.589996   70.753822\n",
      "3        53.529999   53.267731\n",
      "4        45.849998   45.432621\n",
      "...            ...         ...\n",
      "255375   68.080002   67.698105\n",
      "255376   51.849998   51.420372\n",
      "255377   68.989998   68.928719\n",
      "255378   17.549999   17.642155\n",
      "255379   56.259998   56.538441\n",
      "\n",
      "[255380 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29793725708>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating the model by comparing actual and predicted values\n",
    "df = pd.DataFrame({'Actual': y_test.flatten(), 'Predicted': y_pred_test.flatten()})\n",
    "\n",
    "# Visually comparing some values\n",
    "print(df)\n",
    "\n",
    "# Considering only top 50 for plotting\n",
    "df = df.head(50)\n",
    "df.plot.bar(figsize=(16,10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can say that the model's predicted prices are very close to the actual values in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 4\n",
      "Trainable params: 4\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Answer 11\n",
    "\n",
    "# Printing the summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The flatten layer expects a 3-dimensional input and outputs 3 weights. So, the next layer has 3 input weights and 1 \n",
    "# weight of connection with bias. As it has only 1 neuron, it gives us 1*(3+1) = 4 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected = 198.00, Predicted = 198.07\n",
      "Expected = 40.02, Predicted = 40.12\n",
      "Expected = 56.60, Predicted = 56.34\n",
      "Expected = 13.79, Predicted = 13.71\n",
      "Expected = 153.15, Predicted = 153.89\n"
     ]
    }
   ],
   "source": [
    "# Answer 14\n",
    "\n",
    "# Giving new inputs to predict the prices\n",
    "new_data = pd.DataFrame([[198,195.99,199.99],\n",
    "                        [40.330002,39.630001,40.549999],\n",
    "                        [55.93,55.919998,56.810001],\n",
    "                        [13.68,13.55,13.88],\n",
    "                        [154.580002,152.770004,154.699997]], \n",
    "                        columns=['open','low','high'])\n",
    "new_data = scaler.transform(new_data)\n",
    "new_data = np.array(new_data)\n",
    "new_data = new_data.reshape(new_data.shape[0], new_data.shape[1], 1)\n",
    "actuals = [198,40.02,56.599998,13.79,153.149994]\n",
    "predictions = model.predict(new_data)\n",
    "for i in range(5):\n",
    "    print('Expected = %.2f, Predicted = %.2f' % (actuals[i], predictions[i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model is predicting prices quite close to the actual prices. Nevertheless, the loss is around 0.74 which can be\n",
    "# improved. Increasing the number of hidden layers, neurons, modifying the learning rate, adding momentum, etc. might\n",
    "# help us in further reducing the loss."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
